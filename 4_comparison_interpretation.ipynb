{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49036712",
   "metadata": {},
   "source": [
    "1: Imports & Load Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044ba295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Load Train/Test Splits\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Models for comparison\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Visualization (for tree)\n",
    "from sklearn import tree as sktree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load train/test splits (make sure these .pkl files exist in working directory)\n",
    "with open(\"X_train.pkl\", \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open(\"X_test.pkl\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open(\"y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open(\"y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "print(\"✅ Reloaded train/test splits:\")\n",
    "print(f\"  • X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"  • X_test : {X_test.shape},  y_test : {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e258120",
   "metadata": {},
   "source": [
    "2: Retrain Final Pruned Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61425aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain & Evaluate Final Pruned Decision Tree\n",
    "\n",
    "# Best hyperparameters from Member 3\n",
    "alpha_best = 9.679368290900915e-05\n",
    "depth_best = 10\n",
    "split_best = 20\n",
    "\n",
    "# 1. Instantiate pruned DecisionTreeClassifier with those hyperparameters\n",
    "dt_pruned = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=depth_best,\n",
    "    min_samples_split=split_best,\n",
    "    ccp_alpha=alpha_best\n",
    ")\n",
    "\n",
    "# 2. Fit on training data\n",
    "dt_pruned.fit(X_train, y_train)\n",
    "\n",
    "# 3. Evaluate on the test set\n",
    "y_pred_pruned = dt_pruned.predict(X_test)\n",
    "y_proba_pruned = dt_pruned.predict_proba(X_test)[:, 1]\n",
    "pruned_acc = accuracy_score(y_test, y_pred_pruned)\n",
    "pruned_roc_auc = roc_auc_score(y_test, y_proba_pruned)\n",
    "\n",
    "print(\"▶️ Pruned Decision Tree Performance on Test Set:\")\n",
    "print(f\"  • Test Accuracy: {pruned_acc:.4f}\")\n",
    "print(f\"  • Test ROC-AUC : {pruned_roc_auc:.4f}\")\n",
    "print(\"\\n▶️ Pruned Tree Sample Counts (sanity check):\")\n",
    "print(f\"  • Number of nodes: {dt_pruned.tree_.node_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da93cd46",
   "metadata": {},
   "source": [
    "3: Train & Evaluate Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Evaluate Random Forest\n",
    "\n",
    "# 1. Instantiate RandomForest with default hyperparameters (100 trees)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2. Fit on the same training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 3. Predict on test set\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 4. Compute metrics\n",
    "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
    "rf_roc_auc = roc_auc_score(y_test, y_proba_rf)\n",
    "rf_cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "# 5. Print results\n",
    "print(\"▶️ Random Forest Performance on Test Set:\")\n",
    "print(f\"  • Test Accuracy: {rf_acc:.4f}\")\n",
    "print(f\"  • Test ROC-AUC : {rf_roc_auc:.4f}\")\n",
    "print(\"\\n▶️ Random Forest Confusion Matrix:\")\n",
    "print(rf_cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7e33cc",
   "metadata": {},
   "source": [
    "4: Visualize & Interpret the Pruned Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04022bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize & Interpret the Pruned Tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "plot_tree(\n",
    "    dt_pruned,\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=[\"No\", \"Yes\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    max_depth=3,      # adjust to show more or fewer levels\n",
    "    fontsize=12\n",
    ")\n",
    "plt.title(\"Pruned Decision Tree (first 3 levels)\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b621711",
   "metadata": {},
   "source": [
    "Business Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import _tree\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "\n",
    "def print_decision_paths_with_counts(tree_model, X_train, y_train, feature_names):\n",
    "    \n",
    "    # 1. Determine leaf index for each training sample\n",
    "    leaf_indices = tree_model.apply(X_train)  # array of shape (n_train,)\n",
    "    \n",
    "    # 2. Count total and yes samples per leaf\n",
    "    total_counts = Counter(leaf_indices)\n",
    "    yes_counts   = Counter(idx for idx, y in zip(leaf_indices, y_train) if y == 1)\n",
    "    \n",
    "    # 3. Helper to get counts given a node_id (leaf index)\n",
    "    def get_leaf_counts(node_id):\n",
    "        total = total_counts.get(node_id, 0)\n",
    "        yes   = yes_counts.get(node_id, 0)\n",
    "        no    = total - yes\n",
    "        return total, no, yes\n",
    "\n",
    "    tree = tree_model.tree_\n",
    "\n",
    "    def recurse(node, path):\n",
    "        # If this node is not a leaf, split further\n",
    "        if tree.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            feat_idx = tree.feature[node]\n",
    "            threshold = tree.threshold[node]\n",
    "            name = feature_names[feat_idx]\n",
    "\n",
    "            # Left branch: feature ≤ threshold\n",
    "            recurse(tree.children_left[node],\n",
    "                    path + [f\"{name} ≤ {threshold:.3f}\"])\n",
    "            # Right branch: feature > threshold\n",
    "            recurse(tree.children_right[node],\n",
    "                    path + [f\"{name} > {threshold:.3f}\"])\n",
    "        else:\n",
    "            # Leaf node: fetch counts from our dictionaries\n",
    "            total, no_count, yes_count = get_leaf_counts(node)\n",
    "            prediction = 'Yes' if yes_count > no_count else 'No'\n",
    "\n",
    "            # Print the path and leaf stats\n",
    "            print(\"→ \" + \" AND \".join(path))\n",
    "            print(f\"  → Leaf Node: Predict = {prediction} \"\n",
    "                  f\"(samples = {total}, No = {no_count}, Yes = {yes_count})\\n\")\n",
    "\n",
    "    # Start recursion at the root node (index 0)\n",
    "    recurse(0, [])\n",
    "\n",
    "# === Usage ===\n",
    "# Make sure dt_pruned has been trained on X_train, y_train\n",
    "feature_list = list(X_train.columns)\n",
    "print_decision_paths_with_counts(dt_pruned, X_train, y_train, feature_names=feature_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
