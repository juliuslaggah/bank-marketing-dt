{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2785f07c",
   "metadata": {},
   "source": [
    "1: Imports & Load Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"X_train.pkl\", \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open(\"X_test.pkl\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open(\"y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open(\"y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "print(\"✅ Loaded corrected splits:\")\n",
    "print(f\"  • X_train: {X_train.shape}\")\n",
    "print(f\"  • X_test : {X_test.shape}\")\n",
    "print(f\"  • y_train: {y_train.shape}\")\n",
    "print(f\"  • y_test : {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2064506",
   "metadata": {},
   "source": [
    "2: Train & Evaluate Default Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 1. Train the default Decision Tree\n",
    "clf_default = DecisionTreeClassifier(random_state=42)\n",
    "clf_default.fit(X_train, y_train)\n",
    "\n",
    "# 2. Predict on test set\n",
    "y_pred = clf_default.predict(X_test)\n",
    "y_proba = clf_default.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 3. Compute metrics\n",
    "acc   = accuracy_score(y_test, y_pred)\n",
    "prec  = precision_score(y_test, y_pred)\n",
    "rec   = recall_score(y_test, y_pred)\n",
    "f1    = f1_score(y_test, y_pred)\n",
    "roc   = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "# 4. Print results\n",
    "print(\"▶️ Default Decision Tree Performance:\")\n",
    "print(f\"  • Accuracy : {acc:.4f}\")\n",
    "print(f\"  • Precision: {prec:.4f}\")\n",
    "print(f\"  • Recall   : {rec:.4f}\")\n",
    "print(f\"  • F1 Score : {f1:.4f}\")\n",
    "print(f\"  • ROC AUC  : {roc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88bf250",
   "metadata": {},
   "source": [
    "3: Confusion Matrix & ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d218ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix & ROC Curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=False,\n",
    "    xticklabels=['Pred 0', 'Pred 1'],\n",
    "    yticklabels=['True 0', 'True 1']\n",
    ")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title(\"Confusion Matrix: Default Decision Tree\")\n",
    "plt.show()\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(fpr, tpr, label=f\"Default Tree (AUC = {roc:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve: Default Decision Tree\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb19b13",
   "metadata": {},
   "source": [
    "4 – Feature Importance (Top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2edcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance (Top 10)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Extract feature importances into a pandas Series\n",
    "importances = pd.Series(clf_default.feature_importances_, index=X_train.columns)\n",
    "\n",
    "# 2. Select top 10 features by importance\n",
    "top10 = importances.sort_values(ascending=False).head(10)\n",
    "\n",
    "# 3. Plot a horizontal bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "top10.plot(kind=\"barh\", color=\"skyblue\")\n",
    "plt.gca().invert_yaxis()  # highest importance on top\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.title(\"Top 10 Feature Importances: Default Decision Tree\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Print numeric values of the top 10\n",
    "print(\"▶️ Top 10 Feature Importances:\")\n",
    "for feature, score in top10.items():\n",
    "    print(f\"  • {feature}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eca1f10",
   "metadata": {},
   "source": [
    "5 – Visualize a Shallow Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de06792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a Shallow Decision Tree (max_depth=3)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# 1. Train a shallower tree for easier visualization\n",
    "clf_shallow = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf_shallow.fit(X_train, y_train)\n",
    "\n",
    "# 2. Plot the tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    clf_shallow, \n",
    "    feature_names=X_train.columns,\n",
    "    class_names=[\"No\", \"Yes\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=12\n",
    ")\n",
    "plt.title(\"Decision Tree (max_depth=3)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cae7da",
   "metadata": {},
   "source": [
    "5-Fold Cross-Validation on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Cross-Validation on Training Data\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold CV on X_train / y_train\n",
    "cv_scores = cross_val_score(\n",
    "    clf_default,          # the default tree\n",
    "    X_train, \n",
    "    y_train, \n",
    "    cv=5, \n",
    "    scoring=\"accuracy\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"▶️ 5-Fold CV Accuracy on Training Data (Default Tree):\")\n",
    "for i, score in enumerate(cv_scores, start=1):\n",
    "    print(f\"  • Fold {i}: {score:.4f}\")\n",
    "print(f\"  • Mean CV Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
