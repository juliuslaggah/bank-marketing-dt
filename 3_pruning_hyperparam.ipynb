{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81528f7",
   "metadata": {},
   "source": [
    "1: Imports & Load Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8032a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 1: Imports & Load Splits\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load the previously saved train/test splits\n",
    "with open(\"X_train.pkl\", \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open(\"X_test.pkl\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open(\"y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open(\"y_test.pkl\", \"rb\") as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "print(\"✅ Loaded train/test splits (pruned run).\")\n",
    "print(f\"  • X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"  • X_test : {X_test.shape},  y_test : {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52fab2",
   "metadata": {},
   "source": [
    "2: Compute Cost-Complexity Pruning (CCP) Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 2: Compute CCP Path\n",
    "\n",
    "# 1. Train a full (unpruned) decision tree on the training set\n",
    "dt_full = DecisionTreeClassifier(random_state=42)\n",
    "dt_full.fit(X_train, y_train)\n",
    "\n",
    "# 2. Extract the cost-complexity pruning path\n",
    "path = dt_full.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "# 3. Plot Impurity vs. CCP Alpha (to see how impurity grows with alpha)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(ccp_alphas, impurities, marker=\"o\", drawstyle=\"steps-post\")\n",
    "plt.xlabel(\"ccp_alpha\")\n",
    "plt.ylabel(\"Impurity (Total Cost-Complexity)\")\n",
    "plt.title(\"Impurity vs. CCP Alpha (Training Data)\")\n",
    "plt.show()\n",
    "\n",
    "# 4. Select ~15–20 α candidates for grid search (evenly spaced indices)\n",
    "alpha_candidates = ccp_alphas[np.linspace(0, len(ccp_alphas)-1, 15, dtype=int)]\n",
    "print(\"▶️ Selected CCP Alpha candidates:\", np.round(alpha_candidates, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e5c66",
   "metadata": {},
   "source": [
    "3: Hyperparameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Hyperparameter Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. Define the parameter grid\n",
    "param_grid = {\n",
    "    \"max_depth\": [5, 10, 15, None],\n",
    "    \"min_samples_split\": [2, 10, 20],\n",
    "    \"ccp_alpha\": list(alpha_candidates)\n",
    "}\n",
    "\n",
    "# 2. Initialize a Decision Tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 3. Set up 5-fold CV grid search optimizing for ROC-AUC\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# 4. Run the grid search on the training set\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 5. Extract and print best parameters and best CV ROC-AUC\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"▶️ Best Params:\", best_params)\n",
    "print(f\"▶️ Best CV ROC-AUC: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63815dc5",
   "metadata": {},
   "source": [
    "4: Plot CV Results vs. CCP Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 4: CV Curves for CCP Alpha\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Convert the grid search results into a DataFrame\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "# 2. Filter rows for the best max_depth and min_samples_split\n",
    "mask = (\n",
    "    (results[\"param_max_depth\"] == best_params[\"max_depth\"]) &\n",
    "    (results[\"param_min_samples_split\"] == best_params[\"min_samples_split\"])\n",
    ")\n",
    "subset = results[mask].sort_values(by=\"param_ccp_alpha\")\n",
    "\n",
    "# 3. Plot mean_train_score (ROC-AUC) vs. ccp_alpha\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(\n",
    "    subset[\"param_ccp_alpha\"].astype(float), \n",
    "    subset[\"mean_train_score\"], \n",
    "    label=\"Train ROC-AUC\", \n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "# 4. Plot mean_test_score (ROC-AUC) vs. ccp_alpha\n",
    "plt.plot(\n",
    "    subset[\"param_ccp_alpha\"].astype(float), \n",
    "    subset[\"mean_test_score\"], \n",
    "    label=\"Validation ROC-AUC\", \n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"ccp_alpha (log scale)\")\n",
    "plt.ylabel(\"ROC-AUC\")\n",
    "plt.title(\"Train vs. Validation ROC-AUC vs. CCP Alpha\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 5. Print the subset DataFrame for reference (showing the columns of interest)\n",
    "print(\"\\n▶️ Subset of CV results (for best max_depth & min_samples_split):\")\n",
    "print(subset[[\n",
    "    \"param_ccp_alpha\", \"mean_train_score\", \"std_train_score\", \n",
    "    \"mean_test_score\", \"std_test_score\"\n",
    "]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0f4177",
   "metadata": {},
   "source": [
    "5: Train Final Pruned Tree & Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af3f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 5: Train Final Pruned Tree & Evaluate on Test Set\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 1. Extract best hyperparameters\n",
    "alpha_best = best_params[\"ccp_alpha\"]\n",
    "depth_best = best_params[\"max_depth\"]\n",
    "split_best = best_params[\"min_samples_split\"]\n",
    "\n",
    "# 2. Initialize the pruned Decision Tree with those parameters\n",
    "dt_pruned = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    max_depth=depth_best,\n",
    "    min_samples_split=split_best,\n",
    "    ccp_alpha=alpha_best\n",
    ")\n",
    "\n",
    "# 3. Fit on the full training set\n",
    "dt_pruned.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict on the test set\n",
    "y_pred_pruned = dt_pruned.predict(X_test)\n",
    "y_proba_pruned = dt_pruned.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 5. Compute test metrics\n",
    "test_acc = accuracy_score(y_test, y_pred_pruned)\n",
    "test_roc_auc = roc_auc_score(y_test, y_proba_pruned)\n",
    "\n",
    "# 6. Print final performance\n",
    "print(\"▶️ Pruned Decision Tree Performance on Test Set:\")\n",
    "print(f\"  • Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  • Test ROC-AUC : {test_roc_auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
