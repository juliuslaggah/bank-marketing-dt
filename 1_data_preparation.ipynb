{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b28cb6",
   "metadata": {},
   "source": [
    "Step 1. Importing all libries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2acdd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling & Visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc17399",
   "metadata": {},
   "source": [
    "2: Load Dataset and Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3df95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load original raw CSV\n",
    "df = pd.read_csv(\"data/bank-additional-full.csv\", sep=\";\")\n",
    "\n",
    "# 2. Replace any \"unknown\" with NaN\n",
    "df.replace(\"unknown\", np.nan, inplace=True)\n",
    "\n",
    "# 3. Impute all categorical missing values with mode\n",
    "for col in ['job', 'marital', 'education', 'default', 'housing', 'loan']:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# 4. One-hot encode ALL categorical columns (including month, day_of_week, contact, poutcome)\n",
    "#    and drop the first level to avoid redundant columns. \n",
    "#    Leave 'y' untouched for now.\n",
    "cat_cols = ['job', 'marital', 'education', 'default', \n",
    "            'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# 5. Encode target column 'y' to 0/1\n",
    "df_encoded['y'] = df['y'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "# 6. Confirm there are no object dtypes remaining:\n",
    "print(\"➡️ dtypes after encoding:\", df_encoded.dtypes.value_counts())\n",
    "\n",
    "# 7. (Same as before) Drop highly correlated features if necessary:\n",
    "#    Compute correlation matrix and drop 'emp.var.rate' and 'nr.employed'\n",
    "corr_matrix = df_encoded.corr(numeric_only=True)\n",
    "mask_upper = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "high_corr = (corr_matrix.where(mask_upper)\n",
    "             .stack()\n",
    "             .reset_index()\n",
    "             .rename(columns={'level_0': 'f1', 'level_1': 'f2', 0: 'corr'}))\n",
    "high_corr = high_corr.loc[high_corr['corr'].abs() > 0.85]\n",
    "\n",
    "print(\"➡️ Highly correlated pairs (|corr|>0.85):\")\n",
    "print(high_corr)\n",
    "\n",
    "# If the same three remain, drop 'emp.var.rate' and 'nr.employed'\n",
    "df_final = df_encoded.drop(columns=['emp.var.rate', 'nr.employed'], errors='ignore')\n",
    "\n",
    "print(\"➡️ Final DataFrame shape:\", df_final.shape)\n",
    "print(\"➡️ dtypes after dropping:\", df_final.dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077822c",
   "metadata": {},
   "source": [
    "Model Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6520b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Re-Split & Save Pickle Splits (Member 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Separate features and target\n",
    "X = df_final.drop(\"y\", axis=1)\n",
    "y = df_final[\"y\"]\n",
    "\n",
    "print(\"➡️ X shape:\", X.shape, \"| y shape:\", y.shape)\n",
    "\n",
    "# 80/20 stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"➡️ X_train:\", X_train.shape, \"| y_train:\", y_train.shape)\n",
    "print(\"➡️ X_test :\", X_test.shape,  \"| y_test :\", y_test.shape)\n",
    "\n",
    "# Save to disk as .pkl\n",
    "with open(\"X_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open(\"X_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_test, f)\n",
    "with open(\"y_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_train, f)\n",
    "with open(\"y_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_test, f)\n",
    "\n",
    "print(\"✅ Saved new pickle splits.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
